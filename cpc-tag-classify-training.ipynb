{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/shiquda/CPC-tag.git\n",
    "# !mv CPC-tag/* .\n",
    "# !rm -rf CPC-tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import base64\n",
    "import json\n",
    "import os\n",
    "\n",
    "from utils import base64_decode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载并初步处理 CSV 数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Cui2hee6p+eOm+S4vea4uOaIjwrpopjnm67og4zmma8K5p...</td>\n",
       "      <td>[2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>CkErQiBQcm9ibGVtCumimOebruiDjOaZrwrlvLrng4jmjq...</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>CltOT0lQMjAwMiDmma7lj4rnu4RdIOi/h+ays+WNkgrpop...</td>\n",
       "      <td>[3, 82]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>CltOT0lQMjAxMSDmj5Dpq5jnu4RdIOmTuuWcsOavrwrpop...</td>\n",
       "      <td>[1, 83, 111]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>CltOT0lQMjAwMCDmj5Dpq5jnu4RdIOaWueagvOWPluaVsA...</td>\n",
       "      <td>[3, 54, 204]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5464</th>\n",
       "      <td>5465</td>\n",
       "      <td>CltUSFVQQyAyMDI0IOWInei1m10g5YuH6Zev5pyr5pel5a...</td>\n",
       "      <td>[8, 107]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5465</th>\n",
       "      <td>5466</td>\n",
       "      <td>CltUSFVQQyAyMDI0IOWInei1m10g5L2g6K+05b6X5a+577...</td>\n",
       "      <td>[2, 390]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5466</th>\n",
       "      <td>5467</td>\n",
       "      <td>CltVU0FDTzIzREVDXSBDYW5keSBDYW5lIEZlYXN0IEIK6a...</td>\n",
       "      <td>[1, 60]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5467</th>\n",
       "      <td>5468</td>\n",
       "      <td>CltVU0FDTzIzREVDXSBDb3dudGFjdCBUcmFjaW5nIDIgQg...</td>\n",
       "      <td>[7, 45, 60]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5468</th>\n",
       "      <td>5469</td>\n",
       "      <td>CltVU0FDTzIzREVDXSBGYXJtZXIgSm9obiBBY3R1YWxseS...</td>\n",
       "      <td>[5, 60]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5469 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text          tags\n",
       "0        1  Cui2hee6p+eOm+S4vea4uOaIjwrpopjnm67og4zmma8K5p...           [2]\n",
       "1        2  CkErQiBQcm9ibGVtCumimOebruiDjOaZrwrlvLrng4jmjq...           [1]\n",
       "2        3  CltOT0lQMjAwMiDmma7lj4rnu4RdIOi/h+ays+WNkgrpop...       [3, 82]\n",
       "3        4  CltOT0lQMjAxMSDmj5Dpq5jnu4RdIOmTuuWcsOavrwrpop...  [1, 83, 111]\n",
       "4        5  CltOT0lQMjAwMCDmj5Dpq5jnu4RdIOaWueagvOWPluaVsA...  [3, 54, 204]\n",
       "...    ...                                                ...           ...\n",
       "5464  5465  CltUSFVQQyAyMDI0IOWInei1m10g5YuH6Zev5pyr5pel5a...      [8, 107]\n",
       "5465  5466  CltUSFVQQyAyMDI0IOWInei1m10g5L2g6K+05b6X5a+577...      [2, 390]\n",
       "5466  5467  CltVU0FDTzIzREVDXSBDYW5keSBDYW5lIEZlYXN0IEIK6a...       [1, 60]\n",
       "5467  5468  CltVU0FDTzIzREVDXSBDb3dudGFjdCBUcmFjaW5nIDIgQg...   [7, 45, 60]\n",
       "5468  5469  CltVU0FDTzIzREVDXSBGYXJtZXIgSm9obiBBY3R1YWxseS...       [5, 60]\n",
       "\n",
       "[5469 rows x 3 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header = ['id', 'text', 'tags']\n",
    "\n",
    "df = pd.read_csv('./data/algo_problems.csv', header=None, names=header)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>\\n超级玛丽游戏\\n题目背景\\n本题是洛谷的试机题目，可以帮助了解洛谷的使用。\\n\\n建议完...</td>\n",
       "      <td>[2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>\\nA+B Problem\\n题目背景\\n强烈推荐[新用户必读帖](/discuss/sho...</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>\\n[NOIP2002 普及组] 过河卒\\n题目描述\\n棋盘上 $A$ 点有一个过河卒，需要...</td>\n",
       "      <td>[3, 82]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>\\n[NOIP2011 提高组] 铺地毯\\n题目描述\\n为了准备一个独特的颁奖典礼，组织者在...</td>\n",
       "      <td>[1, 83, 111]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>\\n[NOIP2000 提高组] 方格取数\\n题目背景\\nNOIP 2000 提高组 T4\\...</td>\n",
       "      <td>[3, 54, 204]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5464</th>\n",
       "      <td>5465</td>\n",
       "      <td>\\n[THUPC 2024 初赛] 勇闯末日塔\\n题目背景\\n安宁顷刻今将逝，末日黑云伺隙来...</td>\n",
       "      <td>[8, 107]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5465</th>\n",
       "      <td>5466</td>\n",
       "      <td>\\n[THUPC 2024 初赛] 你说得对，但是 AIGC\\n题目背景\\n你说得对，但是*...</td>\n",
       "      <td>[2, 390]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5466</th>\n",
       "      <td>5467</td>\n",
       "      <td>\\n[USACO23DEC] Candy Cane Feast B\\n题目描述\\nFarme...</td>\n",
       "      <td>[1, 60]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5467</th>\n",
       "      <td>5468</td>\n",
       "      <td>\\n[USACO23DEC] Cowntact Tracing 2 B\\n题目描述\\nFar...</td>\n",
       "      <td>[7, 45, 60]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5468</th>\n",
       "      <td>5469</td>\n",
       "      <td>\\n[USACO23DEC] Farmer John Actually Farms B\\n题...</td>\n",
       "      <td>[5, 60]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5469 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text          tags\n",
       "0        1  \\n超级玛丽游戏\\n题目背景\\n本题是洛谷的试机题目，可以帮助了解洛谷的使用。\\n\\n建议完...           [2]\n",
       "1        2  \\nA+B Problem\\n题目背景\\n强烈推荐[新用户必读帖](/discuss/sho...           [1]\n",
       "2        3  \\n[NOIP2002 普及组] 过河卒\\n题目描述\\n棋盘上 $A$ 点有一个过河卒，需要...       [3, 82]\n",
       "3        4  \\n[NOIP2011 提高组] 铺地毯\\n题目描述\\n为了准备一个独特的颁奖典礼，组织者在...  [1, 83, 111]\n",
       "4        5  \\n[NOIP2000 提高组] 方格取数\\n题目背景\\nNOIP 2000 提高组 T4\\...  [3, 54, 204]\n",
       "...    ...                                                ...           ...\n",
       "5464  5465  \\n[THUPC 2024 初赛] 勇闯末日塔\\n题目背景\\n安宁顷刻今将逝，末日黑云伺隙来...      [8, 107]\n",
       "5465  5466  \\n[THUPC 2024 初赛] 你说得对，但是 AIGC\\n题目背景\\n你说得对，但是*...      [2, 390]\n",
       "5466  5467  \\n[USACO23DEC] Candy Cane Feast B\\n题目描述\\nFarme...       [1, 60]\n",
       "5467  5468  \\n[USACO23DEC] Cowntact Tracing 2 B\\n题目描述\\nFar...   [7, 45, 60]\n",
       "5468  5469  \\n[USACO23DEC] Farmer John Actually Farms B\\n题...       [5, 60]\n",
       "\n",
       "[5469 rows x 3 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# base64转换\n",
    "df['text'] = df['text'].apply(base64_decode)\n",
    "\n",
    "# 标签转换\n",
    "\n",
    "df['tags'] = df['tags'].apply(lambda x: json.loads(x))\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备数据和标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from transformers import BertTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 原始数据集（未经过token化的文本和标签）\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    df['text'], df['tags'], test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 标签二值化处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ProgramData\\anaconda3\\envs\\cpc\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:900: UserWarning: unknown class(es) [393, 419] will be ignored\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "train_labels = mlb.fit_transform(train_labels)\n",
    "test_labels = mlb.transform(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 初始化 BERT tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ProgramData\\anaconda3\\envs\\cpc\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing and saving encodings...\n"
     ]
    }
   ],
   "source": [
    "re_encoding = 0\n",
    "\n",
    "# 4. 检查是否有已保存的编码文件\n",
    "if (not re_encoding) and os.path.exists('./data/train_encodings.pt') and os.path.exists('./data/test_encodings.pt'):\n",
    "    print(\"Loading saved encodings...\")\n",
    "    train_encodings = torch.load('./data/train_encodings.pt')\n",
    "    test_encodings = torch.load('./data/test_encodings.pt')\n",
    "else:\n",
    "    print(\"Tokenizing and saving encodings...\")\n",
    "    train_encodings = tokenizer(train_texts.tolist(), truncation=True, padding=True, max_length=512, return_tensors='pt')\n",
    "    test_encodings = tokenizer(test_texts.tolist(), truncation=True, padding=True, max_length=512, return_tensors='pt')\n",
    "    torch.save(train_encodings, './data/train_encodings.pt')\n",
    "    torch.save(test_encodings, './data/test_encodings.pt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建 Dataset 和 DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class AlgoDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.float)\n",
    "        return item\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101,  1031,  8040,  ...,   100,   100,   102],\n",
      "        [  101,  1643, 24665,  ...,   100,   100,   102],\n",
      "        [  101,   100,  1979,  ...,   100,  1000,   102],\n",
      "        ...,\n",
      "        [  101,  1031,  2053,  ...,  1636,   100,   102],\n",
      "        [  101,  1031, 24582,  ...,   100,   100,   102],\n",
      "        [  101,   100,   100,  ...,  1035,  1045,   102]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1]]), 'labels': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 创建训练集和测试集的 Dataset 和 DataLoader\n",
    "train_dataset = AlgoDataset(train_encodings, train_labels)\n",
    "test_dataset = AlgoDataset(test_encodings, test_labels)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "# 打印 DataLoader 中的一个批次样本\n",
    "for batch in train_dataloader:\n",
    "    print(batch)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载 BERT 模型并训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "d:\\ProgramData\\anaconda3\\envs\\cpc\\lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW\n",
    "import torch\n",
    "\n",
    "# 初始化BERT模型，指定多标签分类的输出单元数量\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=train_labels.shape[1])\n",
    "\n",
    "# 将模型移动到GPU（如果有的话）\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)\n",
    "\n",
    "# 定义优化器\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: 100%|██████████| 547/547 [11:19<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 finished, Average Training Loss: 0.2453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3:  95%|█████████▍| 519/547 [09:46<00:30,  1.11s/it]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# 定义训练的epoch数量\n",
    "num_epochs = 3\n",
    "\n",
    "# 训练循环\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # 切换模型到训练模式\n",
    "    total_train_loss = 0\n",
    "    \n",
    "    # 遍历每个批次\n",
    "    for batch in tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}/{num_epochs}\"):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()  # 清空累积的梯度\n",
    "        \n",
    "        # 前向传播\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        total_train_loss += loss.item()\n",
    "        \n",
    "        # 反向传播\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "    print(f\"Epoch {epoch + 1} finished, Average Training Loss: {avg_train_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型\n",
    "torch.save(model.state_dict(), './model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "model.eval()  # 切换模型到评估模式\n",
    "total_val_loss = 0\n",
    "all_preds, all_labels = [], []\n",
    "\n",
    "with torch.no_grad(): \n",
    "    for batch in tqdm(test_dataloader, desc=\"Evaluating\"):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        # 前向传播\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        total_val_loss += loss.item()\n",
    "\n",
    "        # 预测结果\n",
    "        preds = torch.sigmoid(outputs.logits).cpu().numpy()  # 用sigmoid得到概率值\n",
    "        all_preds.extend(preds)\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# 计算平均损失\n",
    "avg_val_loss = total_val_loss / len(test_dataloader)\n",
    "print(f\"Average Validation Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "# 转换预测结果为二进制标签\n",
    "threshold = 0.5\n",
    "binary_preds = [[1 if pred > threshold else 0 for pred in preds] for preds in all_preds]\n",
    "\n",
    "# 计算F1分数或其他指标\n",
    "f1 = f1_score(all_labels, binary_preds, average='micro')\n",
    "accuracy = accuracy_score(all_labels, binary_preds)\n",
    "print(f\"Validation F1 Score: {f1:.4f}\")\n",
    "print(f\"Validation Accuracy: {accuracy:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
