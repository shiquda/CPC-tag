{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/shiquda/CPC-tag.git\n",
    "# !mv CPC-tag/* .\n",
    "# !rm -rf CPC-tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import base64\n",
    "import json\n",
    "import os\n",
    "\n",
    "from utils import base64_decode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载并初步处理 CSV 数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Cui2hee6p+eOm+S4vea4uOaIjwrpopjnm67og4zmma8K5p...</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>CkErQiBQcm9ibGVtCumimOebruiDjOaZrwrlvLrng4jmjq...</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>CltOT0lQMjAwMiDmma7lj4rnu4RdIOi/h+ays+WNkgrpop...</td>\n",
       "      <td>[2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>CltOT0lQMjAxMSDmj5Dpq5jnu4RdIOmTuuWcsOavrwrpop...</td>\n",
       "      <td>[0, 40]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>CltOT0lQMjAwMCDmj5Dpq5jnu4RdIOaWueagvOWPluaVsA...</td>\n",
       "      <td>[2, 23, 93]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5464</th>\n",
       "      <td>5465</td>\n",
       "      <td>CltUSFVQQyAyMDI0IOWInei1m10g5YuH6Zev5pyr5pel5a...</td>\n",
       "      <td>[7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5465</th>\n",
       "      <td>5466</td>\n",
       "      <td>CltUSFVQQyAyMDI0IOWInei1m10g5L2g6K+05b6X5a+577...</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5466</th>\n",
       "      <td>5467</td>\n",
       "      <td>CltVU0FDTzIzREVDXSBDYW5keSBDYW5lIEZlYXN0IEIK6a...</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5467</th>\n",
       "      <td>5468</td>\n",
       "      <td>CltVU0FDTzIzREVDXSBDb3dudGFjdCBUcmFjaW5nIDIgQg...</td>\n",
       "      <td>[6, 17]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5468</th>\n",
       "      <td>5469</td>\n",
       "      <td>CltVU0FDTzIzREVDXSBGYXJtZXIgSm9obiBBY3R1YWxseS...</td>\n",
       "      <td>[4]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5469 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text         tags\n",
       "0        1  Cui2hee6p+eOm+S4vea4uOaIjwrpopjnm67og4zmma8K5p...          [1]\n",
       "1        2  CkErQiBQcm9ibGVtCumimOebruiDjOaZrwrlvLrng4jmjq...          [0]\n",
       "2        3  CltOT0lQMjAwMiDmma7lj4rnu4RdIOi/h+ays+WNkgrpop...          [2]\n",
       "3        4  CltOT0lQMjAxMSDmj5Dpq5jnu4RdIOmTuuWcsOavrwrpop...      [0, 40]\n",
       "4        5  CltOT0lQMjAwMCDmj5Dpq5jnu4RdIOaWueagvOWPluaVsA...  [2, 23, 93]\n",
       "...    ...                                                ...          ...\n",
       "5464  5465  CltUSFVQQyAyMDI0IOWInei1m10g5YuH6Zev5pyr5pel5a...          [7]\n",
       "5465  5466  CltUSFVQQyAyMDI0IOWInei1m10g5L2g6K+05b6X5a+577...          [1]\n",
       "5466  5467  CltVU0FDTzIzREVDXSBDYW5keSBDYW5lIEZlYXN0IEIK6a...          [0]\n",
       "5467  5468  CltVU0FDTzIzREVDXSBDb3dudGFjdCBUcmFjaW5nIDIgQg...      [6, 17]\n",
       "5468  5469  CltVU0FDTzIzREVDXSBGYXJtZXIgSm9obiBBY3R1YWxseS...          [4]\n",
       "\n",
       "[5469 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/algo_problems.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>\\n超级玛丽游戏\\n题目背景\\n本题是洛谷的试机题目，可以帮助了解洛谷的使用。\\n\\n建议完...</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>\\nA+B Problem\\n题目背景\\n强烈推荐[新用户必读帖](/discuss/sho...</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>\\n[NOIP2002 普及组] 过河卒\\n题目描述\\n棋盘上 $A$ 点有一个过河卒，需要...</td>\n",
       "      <td>[2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>\\n[NOIP2011 提高组] 铺地毯\\n题目描述\\n为了准备一个独特的颁奖典礼，组织者在...</td>\n",
       "      <td>[0, 40]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>\\n[NOIP2000 提高组] 方格取数\\n题目背景\\nNOIP 2000 提高组 T4\\...</td>\n",
       "      <td>[2, 23, 93]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5464</th>\n",
       "      <td>5465</td>\n",
       "      <td>\\n[THUPC 2024 初赛] 勇闯末日塔\\n题目背景\\n安宁顷刻今将逝，末日黑云伺隙来...</td>\n",
       "      <td>[7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5465</th>\n",
       "      <td>5466</td>\n",
       "      <td>\\n[THUPC 2024 初赛] 你说得对，但是 AIGC\\n题目背景\\n你说得对，但是*...</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5466</th>\n",
       "      <td>5467</td>\n",
       "      <td>\\n[USACO23DEC] Candy Cane Feast B\\n题目描述\\nFarme...</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5467</th>\n",
       "      <td>5468</td>\n",
       "      <td>\\n[USACO23DEC] Cowntact Tracing 2 B\\n题目描述\\nFar...</td>\n",
       "      <td>[6, 17]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5468</th>\n",
       "      <td>5469</td>\n",
       "      <td>\\n[USACO23DEC] Farmer John Actually Farms B\\n题...</td>\n",
       "      <td>[4]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5469 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text         tags\n",
       "0        1  \\n超级玛丽游戏\\n题目背景\\n本题是洛谷的试机题目，可以帮助了解洛谷的使用。\\n\\n建议完...          [1]\n",
       "1        2  \\nA+B Problem\\n题目背景\\n强烈推荐[新用户必读帖](/discuss/sho...          [0]\n",
       "2        3  \\n[NOIP2002 普及组] 过河卒\\n题目描述\\n棋盘上 $A$ 点有一个过河卒，需要...          [2]\n",
       "3        4  \\n[NOIP2011 提高组] 铺地毯\\n题目描述\\n为了准备一个独特的颁奖典礼，组织者在...      [0, 40]\n",
       "4        5  \\n[NOIP2000 提高组] 方格取数\\n题目背景\\nNOIP 2000 提高组 T4\\...  [2, 23, 93]\n",
       "...    ...                                                ...          ...\n",
       "5464  5465  \\n[THUPC 2024 初赛] 勇闯末日塔\\n题目背景\\n安宁顷刻今将逝，末日黑云伺隙来...          [7]\n",
       "5465  5466  \\n[THUPC 2024 初赛] 你说得对，但是 AIGC\\n题目背景\\n你说得对，但是*...          [1]\n",
       "5466  5467  \\n[USACO23DEC] Candy Cane Feast B\\n题目描述\\nFarme...          [0]\n",
       "5467  5468  \\n[USACO23DEC] Cowntact Tracing 2 B\\n题目描述\\nFar...      [6, 17]\n",
       "5468  5469  \\n[USACO23DEC] Farmer John Actually Farms B\\n题...          [4]\n",
       "\n",
       "[5469 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# base64转换\n",
    "df['text'] = df['text'].apply(base64_decode)\n",
    "\n",
    "# 标签转换\n",
    "\n",
    "df['tags'] = df['tags'].apply(lambda x: json.loads(x))\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备数据和标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ProgramData\\anaconda3\\envs\\cpc\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.1 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"d:\\ProgramData\\anaconda3\\envs\\cpc\\lib\\runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"d:\\ProgramData\\anaconda3\\envs\\cpc\\lib\\runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"d:\\ProgramData\\anaconda3\\envs\\cpc\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"d:\\ProgramData\\anaconda3\\envs\\cpc\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"d:\\ProgramData\\anaconda3\\envs\\cpc\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"d:\\ProgramData\\anaconda3\\envs\\cpc\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"d:\\ProgramData\\anaconda3\\envs\\cpc\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n",
      "    self._run_once()\n",
      "  File \"d:\\ProgramData\\anaconda3\\envs\\cpc\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n",
      "    handle._run()\n",
      "  File \"d:\\ProgramData\\anaconda3\\envs\\cpc\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"d:\\ProgramData\\anaconda3\\envs\\cpc\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"d:\\ProgramData\\anaconda3\\envs\\cpc\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"d:\\ProgramData\\anaconda3\\envs\\cpc\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"d:\\ProgramData\\anaconda3\\envs\\cpc\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"d:\\ProgramData\\anaconda3\\envs\\cpc\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"d:\\ProgramData\\anaconda3\\envs\\cpc\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"d:\\ProgramData\\anaconda3\\envs\\cpc\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"d:\\ProgramData\\anaconda3\\envs\\cpc\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3006, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"d:\\ProgramData\\anaconda3\\envs\\cpc\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3061, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"d:\\ProgramData\\anaconda3\\envs\\cpc\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"d:\\ProgramData\\anaconda3\\envs\\cpc\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3266, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"d:\\ProgramData\\anaconda3\\envs\\cpc\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3445, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"d:\\ProgramData\\anaconda3\\envs\\cpc\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3505, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\shiquda\\AppData\\Local\\Temp\\ipykernel_43612\\4180173136.py\", line 2, in <module>\n",
      "    from transformers import BertTokenizer\n",
      "  File \"d:\\ProgramData\\anaconda3\\envs\\cpc\\lib\\site-packages\\transformers\\__init__.py\", line 26, in <module>\n",
      "    from . import dependency_versions_check\n",
      "  File \"d:\\ProgramData\\anaconda3\\envs\\cpc\\lib\\site-packages\\transformers\\dependency_versions_check.py\", line 16, in <module>\n",
      "    from .utils.versions import require_version, require_version_core\n",
      "  File \"d:\\ProgramData\\anaconda3\\envs\\cpc\\lib\\site-packages\\transformers\\utils\\__init__.py\", line 34, in <module>\n",
      "    from .generic import (\n",
      "  File \"d:\\ProgramData\\anaconda3\\envs\\cpc\\lib\\site-packages\\transformers\\utils\\generic.py\", line 462, in <module>\n",
      "    import torch.utils._pytree as _torch_pytree\n",
      "  File \"d:\\ProgramData\\anaconda3\\envs\\cpc\\lib\\site-packages\\torch\\__init__.py\", line 2120, in <module>\n",
      "    from torch._higher_order_ops import cond\n",
      "  File \"d:\\ProgramData\\anaconda3\\envs\\cpc\\lib\\site-packages\\torch\\_higher_order_ops\\__init__.py\", line 1, in <module>\n",
      "    from .cond import cond\n",
      "  File \"d:\\ProgramData\\anaconda3\\envs\\cpc\\lib\\site-packages\\torch\\_higher_order_ops\\cond.py\", line 5, in <module>\n",
      "    import torch._subclasses.functional_tensor\n",
      "  File \"d:\\ProgramData\\anaconda3\\envs\\cpc\\lib\\site-packages\\torch\\_subclasses\\functional_tensor.py\", line 42, in <module>\n",
      "    class FunctionalTensor(torch.Tensor):\n",
      "  File \"d:\\ProgramData\\anaconda3\\envs\\cpc\\lib\\site-packages\\torch\\_subclasses\\functional_tensor.py\", line 258, in FunctionalTensor\n",
      "    cpu = _conversion_method_template(device=torch.device(\"cpu\"))\n",
      "d:\\ProgramData\\anaconda3\\envs\\cpc\\lib\\site-packages\\torch\\_subclasses\\functional_tensor.py:258: UserWarning: Failed to initialize NumPy: \n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.1 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      " (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
      "  cpu = _conversion_method_template(device=torch.device(\"cpu\"))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from transformers import BertTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 原始数据集（未经过token化的文本和标签）\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    df['text'], df['tags'], test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 标签二值化处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ProgramData\\anaconda3\\envs\\cpc\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:900: UserWarning: unknown class(es) [228] will be ignored\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "train_labels = mlb.fit_transform(train_labels)\n",
    "test_labels = mlb.transform(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 尝试读取已分词的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading saved encodings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shiquda\\AppData\\Local\\Temp\\ipykernel_43612\\3740146308.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  train_encodings = torch.load('./data/train_encodings.pt')\n",
      "C:\\Users\\shiquda\\AppData\\Local\\Temp\\ipykernel_43612\\3740146308.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  test_encodings = torch.load('./data/test_encodings.pt')\n"
     ]
    }
   ],
   "source": [
    "re_encoding = 0 # 是否强制重新编码\n",
    "\n",
    "# 4. 检查是否有已保存的编码文件\n",
    "if (not re_encoding) and os.path.exists('./data/train_encodings.pt') and os.path.exists('./data/test_encodings.pt'):\n",
    "    print(\"Loading saved encodings...\")\n",
    "    train_encodings = torch.load('./data/train_encodings.pt')\n",
    "    test_encodings = torch.load('./data/test_encodings.pt')\n",
    "else:\n",
    "    print(\"Tokenizing and saving encodings...\")\n",
    "    train_encodings = tokenizer(train_texts.tolist(), truncation=True, padding=True, max_length=512, return_tensors='pt')\n",
    "    test_encodings = tokenizer(test_texts.tolist(), truncation=True, padding=True, max_length=512, return_tensors='pt')\n",
    "    torch.save(train_encodings, './data/train_encodings.pt')\n",
    "    torch.save(test_encodings, './data/test_encodings.pt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建 Dataset 和 DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class AlgoDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.float)\n",
    "        return item\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101,   100,   100,  ...,  1020,  1015,   102],\n",
      "        [  101,   100,   100,  ...,  1032,  3393,   102],\n",
      "        [  101,  1031, 27166,  ...,  1003,  1041,   102],\n",
      "        ...,\n",
      "        [  101,  1031,  1044,  ...,   100,  1961,   102],\n",
      "        [  101,  1641,  1829,  ...,  1636,   100,   102],\n",
      "        [  101,  2365,  2063,  ...,  2184,  1010,   102]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1]]), 'labels': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 创建训练集和测试集的 Dataset 和 DataLoader\n",
    "train_dataset = AlgoDataset(train_encodings, train_labels)\n",
    "test_dataset = AlgoDataset(test_encodings, test_labels)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "# 打印 DataLoader 中的一个批次样本\n",
    "for batch in train_dataloader:\n",
    "    print(batch)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载 BERT 模型并训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "d:\\ProgramData\\anaconda3\\envs\\cpc\\lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW\n",
    "import torch\n",
    "\n",
    "# 初始化BERT模型，指定多标签分类的输出单元数量\n",
    "# model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=train_labels.shape[1])\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-multilingual-cased', num_labels=train_labels.shape[1])\n",
    "\n",
    "\n",
    "# 将模型移动到GPU（如果有的话）\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)\n",
    "\n",
    "# 定义优化器\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: 100%|██████████| 547/547 [17:29<00:00,  1.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 finished, Average Training Loss: 0.2138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3: 100%|██████████| 547/547 [11:42<00:00,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 finished, Average Training Loss: 0.0612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3: 100%|██████████| 547/547 [11:38<00:00,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 finished, Average Training Loss: 0.0513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# 定义训练的epoch数量\n",
    "num_epochs = 3\n",
    "\n",
    "# 训练循环\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # 切换模型到训练模式\n",
    "    total_train_loss = 0\n",
    "    \n",
    "    # 遍历每个批次\n",
    "    for batch in tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}/{num_epochs}\"):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()  # 清空累积的梯度\n",
    "        \n",
    "        # 前向传播\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        total_train_loss += loss.item()\n",
    "        \n",
    "        # 反向传播\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "    print(f\"Epoch {epoch + 1} finished, Average Training Loss: {avg_train_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型\n",
    "model.save_pretrained('./model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/137 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Numpy is not available",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m total_val_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# 预测结果\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msigmoid\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogits\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 用sigmoid得到概率值\u001b[39;00m\n\u001b[0;32m     20\u001b[0m all_preds\u001b[38;5;241m.\u001b[39mextend(preds)\n\u001b[0;32m     21\u001b[0m all_labels\u001b[38;5;241m.\u001b[39mextend(labels\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Numpy is not available"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "model.eval()  # 切换模型到评估模式\n",
    "total_val_loss = 0\n",
    "all_preds, all_labels = [], []\n",
    "\n",
    "with torch.no_grad(): \n",
    "    for batch in tqdm(test_dataloader, desc=\"Evaluating\"):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        # 前向传播\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        total_val_loss += loss.item()\n",
    "\n",
    "        # 预测结果\n",
    "        preds = torch.sigmoid(outputs.logits).cpu().numpy()  # 用sigmoid得到概率值\n",
    "        all_preds.extend(preds)\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# 计算平均损失\n",
    "avg_val_loss = total_val_loss / len(test_dataloader)\n",
    "print(f\"Average Validation Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "# 转换预测结果为二进制标签\n",
    "threshold = 0.5\n",
    "binary_preds = [[1 if pred > threshold else 0 for pred in preds] for preds in all_preds]\n",
    "\n",
    "# 计算F1分数或其他指标\n",
    "f1 = f1_score(all_labels, binary_preds, average='micro')\n",
    "accuracy = accuracy_score(all_labels, binary_preds)\n",
    "print(f\"Validation F1 Score: {f1:.4f}\")\n",
    "print(f\"Validation Accuracy: {accuracy:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
